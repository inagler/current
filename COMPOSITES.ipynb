{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0568a8-1db3-466b-b34c-eb578bb359b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np          # fundamental package for scientific computing\n",
    "import xarray as xr\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3c726-ba16-44e1-9843-a36caad4c0ae",
   "metadata": {},
   "source": [
    "### Composite Analysis\n",
    "\n",
    "- compute anomalies\n",
    "- retrieve composite years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f0ca8a-9529-4918-9a75-22b652480bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_*.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546b6309-758f-415c-bb86-fd1d809a7b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1231.001.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1231.003.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1231.004.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1231.020.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1251.010.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1281.010.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1281.012.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1281.015.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1281.017.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1281.020.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1301.001.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1301.015.nc exists\n",
      "/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/composite_1301.019.nc exists\n"
     ]
    }
   ],
   "source": [
    "temp_anomalies  = []\n",
    "salt_anomalies  = []\n",
    "vvel_anomalies  = []\n",
    "vvel_avg_period_1 = []\n",
    "vvel_avg_period_2 = []\n",
    "sigma_anomalies = []\n",
    "hmxl_anomalies  = []\n",
    "shf_anomalies  = []\n",
    "ssh_anomalies  = []\n",
    "sigma_avg_period_1 = []\n",
    "sigma_avg_period_2 = []\n",
    "\n",
    "for i in range(len(files)):\n",
    "    try:\n",
    "        ds = xr.open_dataset(files[i])\n",
    "        print(f\"{files[i]} exists\")\n",
    "        # Do further processing with the dataset 'ds' if needed\n",
    "    except ValueError as e:\n",
    "        print(f\"Error opening dataset from file {files[i]}: {e}\")\n",
    "        # Handle the exception, for example, continue with the next file\n",
    "        continue\n",
    "    \n",
    "    # TEMP\n",
    "    period1_avg_temp = ds['TEMP'].isel(time=slice(0,35)).mean(dim='time')  \n",
    "    period2_avg_temp = ds['TEMP'].isel(time=slice(45,59)).mean(dim='time')\n",
    "    difference_temp = period2_avg_temp - period1_avg_temp\n",
    "    temp_anomalies.append(difference_temp)\n",
    "    \n",
    "    # SALT\n",
    "    period1_avg_salt = ds['SALT'].isel(time=slice(0,35)).mean(dim='time')  \n",
    "    period2_avg_salt = ds['SALT'].isel(time=slice(45,59)).mean(dim='time')\n",
    "    difference_salt = period2_avg_salt - period1_avg_salt\n",
    "    salt_anomalies.append(difference_salt)\n",
    "    \n",
    "    # VVEL\n",
    "    period1_avg_vvel = ds['VVEL'].isel(time=slice(0,35)).mean(dim='time')  \n",
    "    period2_avg_vvel = ds['VVEL'].isel(time=slice(45,59)).mean(dim='time')\n",
    "    difference_vvel = period2_avg_vvel - period1_avg_vvel\n",
    "    vvel_anomalies.append(difference_vvel)\n",
    "    vvel_avg_period_1.append(period1_avg_vvel)\n",
    "    vvel_avg_period_2.append(period2_avg_vvel)\n",
    "    \n",
    "    # SIGMA_2\n",
    "    period1_avg_sigma = ds['SIGMA_2'].isel(time=slice(0,35)).mean(dim='time')  \n",
    "    period2_avg_sigma = ds['SIGMA_2'].isel(time=slice(45,59)).mean(dim='time')\n",
    "    difference_sigma = period2_avg_sigma - period1_avg_sigma\n",
    "    sigma_anomalies.append(difference_sigma)\n",
    "    sigma_avg_period_1.append(period1_avg_sigma)\n",
    "    sigma_avg_period_2.append(period2_avg_sigma)\n",
    "    \n",
    "    # HMXL\n",
    "    period1_avg_hmxl = ds['HMXL'].isel(time=slice(0,35)).mean(dim='time')  \n",
    "    period2_avg_hmxl = ds['HMXL'].isel(time=slice(45,59)).mean(dim='time')\n",
    "    difference_hmxl = period2_avg_hmxl - period1_avg_hmxl\n",
    "    hmxl_anomalies.append(difference_hmxl)\n",
    "    \n",
    "    # SHF\n",
    "    period1_avg_shf = ds['SHF'].isel(time=slice(0,35)).mean(dim='time')  \n",
    "    period2_avg_shf = ds['SHF'].isel(time=slice(45,59)).mean(dim='time')\n",
    "    difference_shf = period2_avg_shf - period1_avg_shf\n",
    "    shf_anomalies.append(difference_shf)\n",
    "    \n",
    "    # SSH\n",
    "    period1_avg_ssh = ds['SSH'].isel(time=slice(0,35)).mean(dim='time')  \n",
    "    period2_avg_ssh = ds['SSH'].isel(time=slice(45,59)).mean(dim='time')\n",
    "    difference_ssh = period2_avg_ssh - period1_avg_ssh\n",
    "    ssh_anomalies.append(difference_ssh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa695100-d17b-4040-ac9c-ee4d928f6545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the list of 3D fields into a single xarray dataset\n",
    "temp_anomaly = xr.concat(temp_anomalies, dim='file').mean(dim='file')\n",
    "salt_anomaly = xr.concat(salt_anomalies, dim='file').mean(dim='file')\n",
    "vvel_anomaly = xr.concat(vvel_anomalies, dim='file').mean(dim='file')\n",
    "vvel_p1 = xr.concat(vvel_avg_period_1, dim='file').mean(dim='file')\n",
    "vvel_p2 = xr.concat(vvel_avg_period_2, dim='file').mean(dim='file')\n",
    "sigma_anomaly = xr.concat(sigma_anomalies, dim='file').mean(dim='file')\n",
    "hmxl_anomaly = xr.concat(hmxl_anomalies, dim='file').mean(dim='file')\n",
    "shf_anomaly = xr.concat(shf_anomalies, dim='file').mean(dim='file')\n",
    "ssh_anomaly = xr.concat(ssh_anomalies, dim='file').mean(dim='file')\n",
    "sigma_p1 = xr.concat(sigma_avg_period_1, dim='file').mean(dim='file')\n",
    "sigma_p2 = xr.concat(sigma_avg_period_2, dim='file').mean(dim='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4997bc-0fb1-4fcd-86be-93d71675b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_anomaly.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/temp_anomaly.nc')\n",
    "salt_anomaly.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/salt_anomaly.nc')\n",
    "vvel_anomaly.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/vvel_anomaly.nc')\n",
    "vvel_p1.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/vvel_p1.nc')\n",
    "vvel_p2.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/vvel_p2.nc')\n",
    "sigma_anomaly.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/sigma_anomaly.nc')\n",
    "hmxl_anomaly.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/hmxl_anomaly.nc')\n",
    "shf_anomaly.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/shf_anomaly.nc')\n",
    "ssh_anomaly.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/ssh_anomaly.nc')\n",
    "sigma_p1.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/sigma_p1.nc')\n",
    "sigma_p2.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/sigma_p2.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c65d9b-5519-4835-af50-465c9e1f59d1",
   "metadata": {},
   "source": [
    "# Density annual composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472fef72-9518-4f07-a352-fb6fddce9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a08be778-fc98-49d3-ae47-9a63512858d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check  1 / 13\n",
      "check  2 / 13\n",
      "check  3 / 13\n",
      "check  4 / 13\n",
      "check  5 / 13\n",
      "check  6 / 13\n",
      "check  7 / 13\n",
      "check  8 / 13\n",
      "check  9 / 13\n",
      "check  10 / 13\n",
      "check  11 / 13\n",
      "check  12 / 13\n",
      "check  13 / 13\n"
     ]
    }
   ],
   "source": [
    "sigma_annual = []\n",
    "\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    ds = xr.open_dataset(files[i])\n",
    "    \n",
    "    # select density from dataset\n",
    "    entire_sigma = ds['SIGMA_2'].isel(time=slice(0,60))\n",
    "    \n",
    "    # fix time coordinate conflict by creating new time coordinate\n",
    "    entire_sigma = entire_sigma.rename({'time': 'new_time'})\n",
    "    entire_sigma['new_time'] = range(60)\n",
    "    if 'time' in entire_sigma.coords:\n",
    "        entire_sigma = entire_sigma.drop('time')\n",
    "    entire_sigma = entire_sigma.rename({'new_time': 'time'})\n",
    "    \n",
    "    # append datarray to list\n",
    "    sigma_annual.append(entire_sigma)\n",
    "    \n",
    "    print('check ', i+1, '/', len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7565014c-0837-4c98-94d2-1fd97e0b34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_annual = xr.concat(sigma_annual, dim='file').mean(dim='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a72960b8-6fef-4c4d-98c0-0c94e611ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_annual.to_netcdf(os.path.expanduser('~/phase1_CONDA/')+'/results/composites/sigma_composite_annual.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

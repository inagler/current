{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8542c235-301a-4b4a-805d-d14d2e72b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import cftime\n",
    "import pop_tools  \n",
    "import gsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4f0305-680c-47bc-823c-56325d83f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose latitude\n",
    "sel_nlat = 345\n",
    "\n",
    "vvel_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/vvel'\n",
    "temp_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/temp'\n",
    "salt_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/salt'\n",
    "\n",
    "output_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/all_member_timeseries'\n",
    "\n",
    "# this is not the most elegant way, it would be better to just give the nlon range\n",
    "grid_name = 'POP_gx1v7'\n",
    "region_defs = {\n",
    "    'SubpolarAtlantic':[{'match': {'REGION_MASK': [6]}, 'bounds': {'TLAT': [45.0, 66.0], 'TLONG': [260.0, 360.0]}}],\n",
    "    'LabradorSea': [{'match': {'REGION_MASK': [8]}, 'bounds': {'TLAT': [45.0, 66.0]}}]}\n",
    "maskSPG = pop_tools.region_mask_3d(grid_name, region_defs=region_defs, mask_name='Subpolar Gyre')\n",
    "maskSPG = maskSPG.sum('region')\n",
    "maskSPG = maskSPG.roll(nlon=-100)\n",
    "\n",
    "def extract_member_id(filename):\n",
    "    match = re.search(r'vvel_([^.]+(?:\\.\\d+)?)\\.nc', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def standardise_time(ds):\n",
    "    ds['time'] = xr.decode_cf(ds, use_cftime=True).time\n",
    "    if isinstance(ds.time.values[0], cftime._cftime.DatetimeNoLeap):\n",
    "        time_as_datetime64 = np.array([pd.Timestamp(str(dt)).to_datetime64() for dt in ds.time.values])\n",
    "        ds['time'] = xr.DataArray(time_as_datetime64, dims='time')\n",
    "    return ds\n",
    "\n",
    "def calculate_sigma2(temp_ds, salt_ds, nlat):\n",
    "    CT = gsw.conversions.CT_from_pt(salt_ds['SALT'].isel(nlat=nlat), temp_ds['TEMP'].isel(nlat=nlat))\n",
    "    sigma2_at_latitude = gsw.density.sigma2(salt_ds['SALT'].isel(nlat=nlat), CT)\n",
    "    sigma2_at_latitude = sigma2_at_latitude.rename('SIGMA_2')\n",
    "    return sigma2_at_latitude\n",
    "\n",
    "def load_and_process_dataset(file_path, mask):\n",
    "    ds = xr.open_dataset(file_path, decode_times=False)\n",
    "    ds = standardise_time(ds)\n",
    "    try:\n",
    "        processed_dataset = ds.roll(nlon=-100).where(mask)\n",
    "    except (RuntimeError, IndexError) as e:\n",
    "        print(f\"Initial processing failed, loading step-by-step: {str(e)}\")\n",
    "        processed_dataset = handle_deprecated_data(ds, mask)\n",
    "    print('process check')\n",
    "    return processed_dataset\n",
    "\n",
    "def handle_deprecated_data(ds, mask):\n",
    "    total_time_steps = ds.dims['time']\n",
    "    last_valid_data = None\n",
    "    for t in range(total_time_steps):\n",
    "        try:\n",
    "            current_data = ds.isel(time=t).load()\n",
    "            last_valid_data = current_data\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error at timestep {t}: {str(e)}\")\n",
    "            if last_valid_data is not None:\n",
    "                current_data = last_valid_data\n",
    "            else:\n",
    "                raise ValueError(f\"No valid data at timestep {t}\")\n",
    "        if t == 0:\n",
    "            combined_data = current_data\n",
    "        else:\n",
    "            combined_data = xr.concat([combined_data, current_data], dim='time')\n",
    "    combined_data['time'] = np.arange(total_time_steps)\n",
    "    result_dataset = combined_data.roll(nlon=-100).where(mask)\n",
    "    return result_dataset\n",
    "    return\n",
    "total_members = len(os.listdir(temp_dir))\n",
    "processed_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f0cc49d-c7ec-4154-b105-b31267f5c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_overturning(vvel_dataset, density_dataset, latitude_index):\n",
    "    density_bins = [12., 16., 20., 24., 28., 28.5, 29.2, 29.4, 29.6, 29.8, 30., 30.2, 30.4, 30.6, 30.8, 31., 31.2, 31.4, 31.6, \n",
    "                   31.8, 32., 32.2, 32.4, 32.6, 32.8, 33., 33.2, 33.4, 33.6, 33.8, 34., 34.2, 34.4, 34.6, 34.8, 35., 35.1, \n",
    "                   35.2, 35.3, 35.4, 35.5, 35.6, 35.7, 35.8, 35.9, 36, 36.1, 36.15, 36.2, 36.25, 36.3, 36.35, 36.4, 36.42, \n",
    "                   36.44, 36.46, 36.48, 36.5, 36.52, 36.54, 36.56, 36.57, 36.58, 36.59, 36.6, 36.61, 36.62, 36.63, 36.64, \n",
    "                   36.65, 36.66, 36.67, 36.68, 36.69, 36.7, 36.71, 36.72, 36.73, 36.74, 36.75, 36.76, 36.78, 36.8, 36.82, \n",
    "                   36.84, 36.86, 36.88, 36.9, 36.92, 36.94, 36.96, 36.98, 37., 37.02, 37.04, 37.06, 37.08, 37.1, 37.12, 37.14, \n",
    "                   37.16, 37.18, 37.2, 37.25, 37.3, 37.35, 37.4, 37.45, 37.6, 37.7, 37.8, 37.9, 38., 39., 40., 41., 42.]\n",
    "    max_overturning_series = []\n",
    "\n",
    "    cell_thickness = vvel_dataset['dz'].isel(nlat=latitude_index)\n",
    "    cell_width = vvel_dataset['DXU'].isel(nlat=latitude_index)\n",
    "    \n",
    "    for time_step in range(len(vvel_dataset.time)):\n",
    "        try:\n",
    "            # compute meridional flow rate for the specified latitude\n",
    "            velocity = vvel_dataset['VVEL'].isel(time=time_step, nlat=latitude_index)\n",
    "            flow_rate = velocity * cell_thickness * cell_width\n",
    "\n",
    "            # compute meridional flow rate and for each density bin and integrate zonally\n",
    "            density_at_time = density_dataset.isel(time=time_step)\n",
    "            flow_rate_by_density = np.zeros(len(density_bins))\n",
    "            for bin_index in range(len(density_bins) - 1):\n",
    "                in_bin = (density_at_time >= density_bins[bin_index]) & (density_at_time < density_bins[bin_index + 1])\n",
    "                flow_rate_by_density[bin_index] = flow_rate.where(in_bin).sum()\n",
    "\n",
    "            # compute density overturning, reverse to integrate from high to low density\n",
    "            density_overturning = np.cumsum(flow_rate_by_density)[::-1]\n",
    "            max_overturning = np.max(density_overturning)\n",
    "            max_overturning_series.append(max_overturning)\n",
    "        except IndexError as e:\n",
    "            print(f\"Error occurred at time step: {time_step}\")\n",
    "            raise e\n",
    "    \n",
    "    max_overturning_dataarray = xr.DataArray(max_overturning_series, dims=[\"time\"], coords={\"time\": vvel_dataset['time']})\n",
    "    return max_overturning_dataarray  * 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6026d3e-68cb-4f69-9d20-c6258bf5a73f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231.001\n",
      "process check\n",
      "temp check\n",
      "process check\n",
      "salt check\n",
      "sigma check\n",
      "process check\n",
      "vvel check\n"
     ]
    }
   ],
   "source": [
    "counter =0\n",
    "\n",
    "for file in os.listdir(vvel_dir):\n",
    "    counter += 1\n",
    "    \n",
    "    if counter == 2:\n",
    "    \n",
    "        member_id = extract_member_id(file)\n",
    "        vvel_path = os.path.join(vvel_dir, file)\n",
    "        temp_path = os.path.join(temp_dir, f'temp_{member_id}.nc')\n",
    "        salt_path = os.path.join(salt_dir, f'salt_{member_id}.nc')\n",
    "        \n",
    "        print(member_id)\n",
    "\n",
    "        temp_ds = load_and_process_dataset(temp_path, maskSPG)\n",
    "        print('temp check')\n",
    "        salt_ds = load_and_process_dataset(salt_path, maskSPG)\n",
    "        print('salt check')\n",
    "        sigma_da = calculate_sigma2(temp_ds, salt_ds, sel_nlat)\n",
    "        print('sigma check')\n",
    "        vvel_ds = load_and_process_dataset(vvel_path, maskSPG)\n",
    "        print('vvel check')\n",
    "\n",
    "        max_overturning_series = density_overturning(vvel_ds, sigma_da, sel_nlat)\n",
    "        print('smoc check')\n",
    "\n",
    "        break\n",
    "    \n",
    "print('')\n",
    "print('computation complete')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894f68f-e71c-4bb2-b1ce-727afd30cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_overturning_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f2688-794d-40c8-81ea-4675862abb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d2227b0-2346-4849-8577-66badac072cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/salt/salt_1231.001.nc', decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af552f6a-b5a2-4bde-8e66-d8d7b7f04314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2460"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.dims['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfc547-9917-444d-95a3-0f6b54e9c83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a52b57b-5650-4dd0-a27d-36918eb641a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: salt_1001.001.nc, Time dimension length: 3012\n",
      "File: salt_1231.001.nc, Time dimension length: 2460\n",
      "File: salt_1231.002.nc, Time dimension length: 3012\n",
      "File: salt_1231.003.nc, Time dimension length: 3012\n",
      "File: salt_1231.004.nc, Time dimension length: 3012\n",
      "File: salt_1231.005.nc, Time dimension length: 3012\n",
      "File: salt_1231.006.nc, Time dimension length: 1980\n",
      "File: salt_1231.007.nc, Time dimension length: 2100\n",
      "File: salt_1231.008.nc, Time dimension length: 3012\n",
      "File: salt_1231.009.nc, Time dimension length: 1980\n",
      "File: salt_1231.010.nc, Time dimension length: 3012\n",
      "File: salt_1231.011.nc, Time dimension length: 3012\n",
      "File: salt_1231.012.nc, Time dimension length: 3012\n",
      "File: salt_1231.013.nc, Time dimension length: 3012\n",
      "File: salt_1231.014.nc, Time dimension length: 3012\n",
      "File: salt_1231.015.nc, Time dimension length: 3012\n",
      "File: salt_1231.016.nc, Time dimension length: 3012\n",
      "File: salt_1231.017.nc, Time dimension length: 3012\n",
      "File: salt_1231.018.nc, Time dimension length: 3012\n",
      "File: salt_1231.019.nc, Time dimension length: 3012\n",
      "File: salt_1231.020.nc, Time dimension length: 3012\n",
      "File: salt_1251.001.nc, Time dimension length: 2340\n",
      "File: salt_1251.002.nc, Time dimension length: 1980\n",
      "File: salt_1251.003.nc, Time dimension length: 1980\n",
      "File: salt_1251.004.nc, Time dimension length: 2100\n",
      "File: salt_1251.005.nc, Time dimension length: 3012\n",
      "File: salt_1251.006.nc, Time dimension length: 3012\n",
      "File: salt_1251.007.nc, Time dimension length: 3012\n",
      "File: salt_1251.008.nc, Time dimension length: 3012\n",
      "File: salt_1251.009.nc, Time dimension length: 3012\n",
      "File: salt_1251.010.nc, Time dimension length: 3012\n",
      "File: salt_1251.011.nc, Time dimension length: 1980\n",
      "File: salt_1251.012.nc, Time dimension length: 1980\n",
      "File: salt_1251.013.nc, Time dimension length: 1980\n",
      "File: salt_1251.014.nc, Time dimension length: 1980\n",
      "File: salt_1251.015.nc, Time dimension length: 1980\n",
      "File: salt_1251.016.nc, Time dimension length: 1980\n",
      "File: salt_1251.017.nc, Time dimension length: 1980\n",
      "File: salt_1251.018.nc, Time dimension length: 1980\n",
      "File: salt_1251.019.nc, Time dimension length: 1980\n",
      "File: salt_1251.020.nc, Time dimension length: 1980\n",
      "File: salt_1281.001.nc, Time dimension length: 3012\n",
      "File: salt_1281.002.nc, Time dimension length: 3012\n",
      "File: salt_1281.003.nc, Time dimension length: 3012\n",
      "File: salt_1281.004.nc, Time dimension length: 3012\n",
      "File: salt_1281.005.nc, Time dimension length: 3012\n",
      "File: salt_1281.006.nc, Time dimension length: 3012\n",
      "File: salt_1281.007.nc, Time dimension length: 3012\n",
      "File: salt_1281.008.nc, Time dimension length: 3012\n",
      "File: salt_1281.009.nc, Time dimension length: 3012\n",
      "File: salt_1281.010.nc, Time dimension length: 3012\n",
      "File: salt_1281.011.nc, Time dimension length: 1032\n",
      "File: salt_1281.012.nc, Time dimension length: 3012\n",
      "File: salt_1281.013.nc, Time dimension length: 3012\n",
      "File: salt_1281.014.nc, Time dimension length: 3012\n",
      "File: salt_1281.015.nc, Time dimension length: 3012\n",
      "File: salt_1281.016.nc, Time dimension length: 3012\n",
      "File: salt_1281.017.nc, Time dimension length: 3012\n",
      "File: salt_1281.018.nc, Time dimension length: 3012\n",
      "File: salt_1281.019.nc, Time dimension length: 3012\n",
      "File: salt_1281.020.nc, Time dimension length: 3012\n",
      "File: salt_1301.001.nc, Time dimension length: 3012\n",
      "File: salt_1301.002.nc, Time dimension length: 3012\n",
      "File: salt_1301.003.nc, Time dimension length: 3012\n",
      "File: salt_1301.004.nc, Time dimension length: 3012\n",
      "File: salt_1301.005.nc, Time dimension length: 3012\n",
      "File: salt_1301.006.nc, Time dimension length: 3012\n",
      "File: salt_1301.007.nc, Time dimension length: 3012\n",
      "File: salt_1301.008.nc, Time dimension length: 3012\n",
      "File: salt_1301.009.nc, Time dimension length: 3012\n",
      "File: salt_1301.010.nc, Time dimension length: 3012\n",
      "File: salt_1301.011.nc, Time dimension length: 3012\n",
      "File: salt_1301.012.nc, Time dimension length: 3012\n",
      "File: salt_1301.013.nc, Time dimension length: 3012\n",
      "File: salt_1301.014.nc, Time dimension length: 3012\n",
      "File: salt_1301.015.nc, Time dimension length: 3012\n",
      "File: salt_1301.016.nc, Time dimension length: 3012\n",
      "File: salt_1301.017.nc, Time dimension length: 3012\n",
      "File: salt_1301.018.nc, Time dimension length: 3012\n",
      "File: salt_1301.019.nc, Time dimension length: 3012\n",
      "File: salt_1301.020.nc, Time dimension length: 3012\n"
     ]
    }
   ],
   "source": [
    "def get_time_dimension_length(file_path):\n",
    "    ds = xr.open_dataset(file_path, decode_times=False)\n",
    "    time_length = ds.dims.get('time', 0)  \n",
    "    ds.close() \n",
    "    return time_length\n",
    "\n",
    "folder_path = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/salt/'\n",
    "time_lengths = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".nc\"): \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            time_length = get_time_dimension_length(file_path)\n",
    "            time_lengths.append((filename, time_length))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "for filename, length in time_lengths:\n",
    "    print(f\"File: {filename}, Time dimension length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa877ed0-c3de-4252-983a-40df44a32726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b40f06-a929-472f-aa8d-688f45c52931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b54545-3e68-42c9-9832-82f87ed9696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at time step: 2460\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2460 is out of bounds for axis 0 with size 2460",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m max_overturning_series \u001b[38;5;241m=\u001b[39m \u001b[43mdensity_overturning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvvel_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_da\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msel_nlat\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mdensity_overturning\u001b[0;34m(vvel_dataset, density_dataset, latitude_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred at time step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     35\u001b[0m max_overturning_dataarray \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(max_overturning_series, dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m], coords\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: vvel_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_overturning_dataarray  \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mdensity_overturning\u001b[0;34m(vvel_dataset, density_dataset, latitude_index)\u001b[0m\n\u001b[1;32m     18\u001b[0m flow_rate \u001b[38;5;241m=\u001b[39m velocity \u001b[38;5;241m*\u001b[39m cell_thickness \u001b[38;5;241m*\u001b[39m cell_width\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# compute meridional flow rate and for each density bin and integrate zonally\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m density_at_time \u001b[38;5;241m=\u001b[39m \u001b[43mdensity_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m flow_rate_by_density \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(density_bins))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bin_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(density_bins) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/movie/lib/python3.10/site-packages/xarray/core/dataarray.py:1397\u001b[0m, in \u001b[0;36mDataArray.isel\u001b[0;34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;66;03m# Much faster algorithm for when all indexers are ints, slices, one-dimensional\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;66;03m# lists, or zero or one-dimensional np.ndarray's\u001b[39;00m\n\u001b[0;32m-> 1397\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1398\u001b[0m indexes, index_variables \u001b[38;5;241m=\u001b[39m isel_indexes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxindexes, indexers)\n\u001b[1;32m   1400\u001b[0m coords \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.conda/envs/movie/lib/python3.10/site-packages/xarray/core/variable.py:1322\u001b[0m, in \u001b[0;36mVariable.isel\u001b[0;34m(self, indexers, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m indexers \u001b[38;5;241m=\u001b[39m drop_dims_from_indexers(indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims, missing_dims)\n\u001b[1;32m   1321\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(indexers\u001b[38;5;241m.\u001b[39mget(dim, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[0;32m-> 1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/movie/lib/python3.10/site-packages/xarray/core/variable.py:870\u001b[0m, in \u001b[0;36mVariable.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;124;03m\"\"\"Return a new Variable object whose contents are consistent with\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;124;03mgetting the provided key from the underlying data.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;124;03marray `x.values` directly.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    869\u001b[0m dims, indexer, new_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_indexes(key)\n\u001b[0;32m--> 870\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mas_indexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_order:\n\u001b[1;32m    872\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(data, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_order)), new_order)\n",
      "File \u001b[0;32m~/.conda/envs/movie/lib/python3.10/site-packages/xarray/core/indexing.py:1264\u001b[0m, in \u001b[0;36mNumpyIndexingAdapter.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1263\u001b[0m     array, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indexing_array_and_key(key)\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2460 is out of bounds for axis 0 with size 2460"
     ]
    }
   ],
   "source": [
    "max_overturning_series = density_overturning(vvel_ds, sigma_da, sel_nlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46957b63-0ffe-43e6-a45f-6de5bd5e22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_bins = [12., 16., 20., 24., 28., 28.5, 29.2, 29.4, 29.6, 29.8, 30., 30.2, 30.4, 30.6, 30.8, 31., 31.2, 31.4, 31.6, \n",
    "                   31.8, 32., 32.2, 32.4, 32.6, 32.8, 33., 33.2, 33.4, 33.6, 33.8, 34., 34.2, 34.4, 34.6, 34.8, 35., 35.1, \n",
    "                   35.2, 35.3, 35.4, 35.5, 35.6, 35.7, 35.8, 35.9, 36, 36.1, 36.15, 36.2, 36.25, 36.3, 36.35, 36.4, 36.42, \n",
    "                   36.44, 36.46, 36.48, 36.5, 36.52, 36.54, 36.56, 36.57, 36.58, 36.59, 36.6, 36.61, 36.62, 36.63, 36.64, \n",
    "                   36.65, 36.66, 36.67, 36.68, 36.69, 36.7, 36.71, 36.72, 36.73, 36.74, 36.75, 36.76, 36.78, 36.8, 36.82, \n",
    "                   36.84, 36.86, 36.88, 36.9, 36.92, 36.94, 36.96, 36.98, 37., 37.02, 37.04, 37.06, 37.08, 37.1, 37.12, 37.14, \n",
    "                   37.16, 37.18, 37.2, 37.25, 37.3, 37.35, 37.4, 37.45, 37.6, 37.7, 37.8, 37.9, 38., 39., 40., 41., 42.]\n",
    "    max_overturning_series = []\n",
    "\n",
    "    cell_thickness = vvel_dataset['dz'].isel(nlat=latitude_index)\n",
    "    cell_width = vvel_dataset['DXU'].isel(nlat=latitude_index)\n",
    "    \n",
    "    for time_step in range(len(vvel_dataset.time)):\n",
    "        try:\n",
    "            # compute meridional flow rate for the specified latitude\n",
    "            velocity = vvel_dataset['VVEL'].isel(time=time_step, nlat=latitude_index)\n",
    "            flow_rate = velocity * cell_thickness * cell_width\n",
    "\n",
    "            # compute meridional flow rate and for each density bin and integrate zonally\n",
    "            density_at_time = density_dataset.isel(time=time_step)\n",
    "            flow_rate_by_density = np.zeros(len(density_bins))\n",
    "            for bin_index in range(len(density_bins) - 1):\n",
    "                in_bin = (density_at_time >= density_bins[bin_index]) & (density_at_time < density_bins[bin_index + 1])\n",
    "                flow_rate_by_density[bin_index] = flow_rate.where(in_bin).sum()\n",
    "\n",
    "            # compute density overturning, reverse to integrate from high to low density\n",
    "            density_overturning = np.cumsum(flow_rate_by_density)[::-1]\n",
    "            max_overturning = np.max(density_overturning)\n",
    "            max_overturning_series.append(max_overturning)\n",
    "        except IndexError as e:\n",
    "            print(f\"Error occurred at time step: {time_step}\")\n",
    "            raise e\n",
    "    \n",
    "    max_overturning_dataarray = xr.DataArray(max_overturning_series, dims=[\"time\"], coords={\"time\": vvel_dataset['time']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c1eb5-804f-4bb8-8189-bb070ef6d1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b1cdd-c2fa-433c-a69a-b41c0014316c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc181a-79aa-4ca9-a3ba-0b62834fe315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441301b-61f5-4837-8651-feccb939db54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfebea1-3aeb-47a6-999b-018233c9d8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56772277-2485-4102-ad38-842bee2c0748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8139c99-6e46-47fc-a2ad-f5226e6dfd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1460960-d1cc-448a-88e2-8049a349f5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd5bfe-d2df-47cf-9f53-89b8851d21b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8a7b0-0e28-4690-9af4-40a822f41495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd375932-3316-4406-80a2-d89ac54f9392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a02c9-0dd7-4970-a2a6-5b7b4b6d20b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a8c3c-715c-42f5-b4ef-8d549b78e1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0470339c-7433-4d6f-8cdf-0fa4a22dad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# choose latitude\n",
    "sel_nlat = 345\n",
    "\n",
    "vvel_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/vvel'\n",
    "temp_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/temp'\n",
    "salt_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/salt'\n",
    "\n",
    "output_dir = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/comp/all_member_timeseries'\n",
    "\n",
    "# this is not the most elegant way, it would be better to just give the nlon range\n",
    "grid_name = 'POP_gx1v7'\n",
    "region_defs = {\n",
    "    'SubpolarAtlantic':[\n",
    "        {'match': {'REGION_MASK': [6]}, 'bounds': {'TLAT': [45.0, 66.0]}}\n",
    "    ],\n",
    "    'LabradorSea': [\n",
    "        {'match': {'REGION_MASK': [8]}, 'bounds': {'TLAT': [45.0, 66.0]}}\n",
    "    ]\n",
    "}\n",
    "maskSPG = pop_tools.region_mask_3d(grid_name, region_defs=region_defs, mask_name='Subpolar Gyre')\n",
    "maskSPG = maskSPG.sum('region')\n",
    "maskSPG = maskSPG.roll(nlon=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52056d28-3dd6-47eb-b4df-a4cfc221ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'vvel_1001.001.nc'\n",
    "ds_test = xr.open_dataset('/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/vvel/'+file)\n",
    "ds_test.roll(nlon=-100).where(maskSPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33c23e-e7e3-4f01-908d-6b6f9528c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_member_id(filename):\n",
    "    match = re.search(r'vvel_([^.]+(?:\\.\\d+)?)\\.nc', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def standardise_time(ds):\n",
    "    ds['time'] = xr.decode_cf(ds, use_cftime=True).time\n",
    "    if isinstance(ds.time.values[0], cftime._cftime.DatetimeNoLeap):\n",
    "        time_as_datetime64 = np.array([pd.Timestamp(str(dt)).to_datetime64() for dt in ds.time.values])\n",
    "        ds['time'] = xr.DataArray(time_as_datetime64, dims='time')\n",
    "    return ds\n",
    "\n",
    "def calculate_sigma2(temp_ds, salt_ds, nlat):\n",
    "    CT = gsw.conversions.CT_from_pt(salt_ds['SALT'].isel(nlat=nlat), temp_ds['TEMP'].isel(nlat=nlat))\n",
    "    sigma2_at_latitude = gsw.density.sigma2(salt_ds['SALT'].isel(nlat=nlat), CT)\n",
    "    return sigma2_at_latitude\n",
    "\n",
    "def load_and_process_dataset(file_path, mask, variable):\n",
    "    '''\n",
    "    ATTENTION\n",
    "    \n",
    "    time range is shortened\n",
    "    \n",
    "    '''\n",
    "    ds = xr.open_dataset(file_path, decode_times=False).isel(time=range(0,10))\n",
    "    ds = standardise_time(ds)\n",
    "    try:\n",
    "        processed_dataset = ds.where(mask)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Initial processing failed, loading step-by-step: {str(e)}\")\n",
    "        processed_dataset = handle_deprecated_data(ds, mask)\n",
    "    return processed_dataset\n",
    "\n",
    "def handle_deprecated_data(ds, mask):\n",
    "    total_time_steps = ds.dims['time']\n",
    "    last_valid_data = None\n",
    "    for t in range(total_time_steps):\n",
    "        try:\n",
    "            current_data = ds.isel(time=t).load()\n",
    "            last_valid_data = current_data\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error at timestep {t}: {str(e)}\")\n",
    "            if last_valid_data is not None:\n",
    "                current_data = last_valid_data\n",
    "            else:\n",
    "                raise ValueError(f\"No valid data at timestep {t}\")\n",
    "        if t == 0:\n",
    "            combined_data = current_data\n",
    "        else:\n",
    "            combined_data = xr.concat([combined_data, current_data], dim='time')\n",
    "    combined_data['time'] = np.arange(total_time_steps)\n",
    "    result_dataset = combined_data.where(mask, drop=True)\n",
    "    return result_dataset\n",
    "total_members = len(os.listdir(temp_dir))\n",
    "processed_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf5d7b-bac8-4730-91d8-d08f94da0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'vvel_1001.001.nc'\n",
    "\n",
    "member_id = extract_member_id(file)\n",
    "vvel_path = os.path.join(vvel_dir, file)\n",
    "temp_path = os.path.join(temp_dir, f'temp_{member_id}.nc')\n",
    "salt_path = os.path.join(salt_dir, f'salt_{member_id}.nc')\n",
    "\n",
    "temp_ds = load_and_process_dataset(temp_path, maskSPG, 'TEMP')\n",
    "salt_ds = load_and_process_dataset(salt_path, maskSPG, 'SALT')\n",
    "sigma_da = calculate_sigma2(temp_ds, salt_ds, sel_nlat)\n",
    "vvel_ds = load_and_process_dataset(vvel_path, maskSPG, 'VVEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca582183-d31b-45a1-8dea-afc15dfbf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "vvel_ds.VVEL.isel(time=0, z_t=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19062837-6799-4778-aefd-70e40054ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vvel_ds.VVEL.mean(dim=['z_t','nlat','nlon']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c80a4-fd71-4731-8a02-062e7bd6d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_index=345\n",
    "\n",
    "density_bins = [12., 16., 20., 24., 28., 28.5, 29.2, 29.4, 29.6, 29.8, 30., 30.2, 30.4, 30.6, 30.8, 31., 31.2, 31.4, 31.6, \n",
    "                   31.8, 32., 32.2, 32.4, 32.6, 32.8, 33., 33.2, 33.4, 33.6, 33.8, 34., 34.2, 34.4, 34.6, 34.8, 35., 35.1, \n",
    "                   35.2, 35.3, 35.4, 35.5, 35.6, 35.7, 35.8, 35.9, 36, 36.1, 36.15, 36.2, 36.25, 36.3, 36.35, 36.4, 36.42, \n",
    "                   36.44, 36.46, 36.48, 36.5, 36.52, 36.54, 36.56, 36.57, 36.58, 36.59, 36.6, 36.61, 36.62, 36.63, 36.64, \n",
    "                   36.65, 36.66, 36.67, 36.68, 36.69, 36.7, 36.71, 36.72, 36.73, 36.74, 36.75, 36.76, 36.78, 36.8, 36.82, \n",
    "                   36.84, 36.86, 36.88, 36.9, 36.92, 36.94, 36.96, 36.98, 37., 37.02, 37.04, 37.06, 37.08, 37.1, 37.12, 37.14, \n",
    "                   37.16, 37.18, 37.2, 37.25, 37.3, 37.35, 37.4, 37.45, 37.6, 37.7, 37.8, 37.9, 38., 39., 40., 41., 42.]\n",
    "cell_thickness = vvel_ds['dz'].isel(nlat=latitude_index)\n",
    "cell_width = vvel_ds['DXU'].isel(nlat=latitude_index)\n",
    "\n",
    "max_overturning_series = []\n",
    "\n",
    "for time_step in range(len(vvel_ds.time)):\n",
    "\n",
    "    # compute meridional flow rate for the specified latitude\n",
    "    velocity = vvel_ds['VVEL'].isel(time=time_step, nlat=latitude_index)\n",
    "    flow_rate = velocity * cell_thickness * cell_width\n",
    "\n",
    "    # compute meridional flow rate and for each density bin and integrate zonally\n",
    "    density_at_time = sigma_da.isel(time=time_step)\n",
    "    flow_rate_by_density = np.zeros(len(density_bins))\n",
    "    for bin_index in range(len(density_bins) - 1):\n",
    "        in_bin = (density_at_time >= density_bins[bin_index]) & (density_at_time < density_bins[bin_index + 1])\n",
    "        flow_rate_by_density[bin_index] = flow_rate.where(in_bin).sum()\n",
    "\n",
    "    # compute density overturning, reverse to integrate from high to low density\n",
    "    density_overturning = np.cumsum(flow_rate_by_density)[::-1]\n",
    "    max_overturning = np.max(density_overturning)\n",
    "    max_overturning_series.append(max_overturning)\n",
    "\n",
    "max_overturning_dataarray = xr.DataArray(max_overturning_series, dims=[\"time\"], coords={\"time\": vvel_ds['time']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d1470-c419-46b3-8683-24b936787d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_overturning_dataarray.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2abbdc2-f3a1-4a99-8e19-9e24fe747121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
